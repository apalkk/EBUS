# EBUS
Event Based Underwater Simulation

The underwater domain presents a vast array of challenges for roboticists and computer vision researchers alike, such as poor lighting conditions and occluded backgrounds. In these adverse conditions, traditional vision techniques struggle to adapt and lead to suboptimal performance. 

Event-based cameras present an attractive solution to this problem, mitigating the issues of traditional cameras by tracking changes in the footage on a frame-by-frame basis. In this paper, we introduce a pipeline which can be used to generate convincing synthetic data of an event-based camera mounted to an edge device in an underwater environment for a vision model. We demonstrate the effectiveness of our pipeline using the task of rock detection with poor visibility and suspended particulate matter, but the approach can be generalized to other underwater tasks. 
